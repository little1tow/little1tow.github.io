<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Neural Network for Named Entity Typing方法总结]]></title>
    <url>%2F2018%2F07%2F04%2F2018-07-04%2F</url>
    <content type="text"><![CDATA[相关文章 Neural Architectures for Fine-grained Entity Type Classification Neural Fine-Grained Entity Type Classification with Hierarchy-Aware Loss Fine-grained Entity Typing through Increased Discourse Context and Adaptive Classification Thresholds 文章1模型图 这是相对来说比较早的一篇利用神经网络来解决NET问题的工作，从模型中大致可以看出该模型的基本框架，1）预训练的词向量进行embedding，2）针对entity mention周边的context，分别使用不同的Bi-LSTM进行处理，并在其隐层状态上使用attention，最后得到context的向量表示，针对entity mention，直接使用平均的方法，将所有词的向量加起来，得到entity mention的向量表示，最后使用一个MLP进行分类。 亮点文章在考虑label的时候，使用了hierarchical label encoding的方法，具体来讲，fine-gained label具有先天的层次化特征，例如person/artist/actor，如果预测entity mention的label为actor，那么理论上是可以回溯上去的，得到person/artist，因此作者考虑将这些信息进行层次化联合编码，还是使用one-hot的表示方法，不过对应的label都会得到1，因此一个label中不只有一个1，然后乘以一个embedding矩阵，得到label的低维表示，然后将得到的低维表示作为最后分类层的参数，进行分类，这个就很有意思了，具体实现过程，可以参见下图： 文章2问题 噪声问题 NET任务有一个很大的问题，那就是数据的问题，目前常用的几个数据集，FIGER，OntoNote，WiKi基本上都是通过如下步骤生成的： 在句子或者文档中使用NER等工具标记entity mention 将得到的entity mention和知识图谱中的entities做关联 找到知识图谱中每个entity的类型，将其作为目标entity mention的候选类型 从这个流程中就可以看出来一个问题，得到的type类型有很高的噪声，而且针对一句特定的句子或文档，这些候选类型中后很多是不符合情境的，也就是说上面的方法在做标注的时候是无法考虑情境的，例如下图 如果只考虑句子s1，那么得到的type就应该是person/coach，如果只考虑句子s2，那能得到的type就应该是athlete， 标注过细问题 还是上图的例子，如果只考虑句子s3，那么得到的就只能是person，但是由于这个人是个名人，因此在知识图谱上会给他标记上很多很细的type，这会导致在训练的时候，模型会更喜欢分这些很细的类别，而不是一般的，但是符合句子情境的类别。 针对以上问题，作者提出了自己的模型，关键的地方在于作者设计的loss function 模型 这个模型还是很简单的，相对于上一个模型，在该模型中，作者将考虑的重点放在了entity mention上边，具体流程如下： embedding layer将句子中的每个词进行embedding 针对entity mention，a）将所有词的向量做平均，得到 一个表示；b）在entity mention的基础上左右各扩展一个词，然后将得到的这个短语通过一个LSTM，然后将最后一个状态作为entity mention的另一种表示 针对context，不再是考虑使用不同的LSTM来处理两边的内容，而是处理整个句子，然后在隐层状态上做attention，最后得到一个加权和作为context的表示，这里的attention是在整个句子上做self-attention。 将得到的三个向量作拼接，然后将结果送给分类器进行分类 损失函数针对数据上存在的两个问题，作者在损失函数上做了一些巧妙地调整。 out-of-context noise 针对这个问题，作者在计算损失时，不是考虑所有类别上的损失，即传统的loss function $$J(\theta) = \frac{1}{N}\sum_{i=1}^{N}y_ilog(p(y_i|m_i, c_i)) + \lambda||\theta||^2, \quad \tag{1}$$ 在这个公式里，$y_i$是一个向量。作者只考虑其中概率最大的类别，即$y_i^{‘} = argmax_{y\in y_i^t}p(y|m_i, c_i)$，这样损失函数就变成了 $$J(\theta) = \frac{1}{N}\sum_{i=1}^{N}(y_i^{‘}log(p(y_i^{‘}|m_i, c_i)))+ \lambda||\theta||^2, \quad \tag{2}$$ 作者这么做，是假设在训练集中获得概率最高的类别是真正符合情境的类别，而概率比较低的类别就和情境不太搭了，这其实也是有一定 道理的，而且很巧妙地将情境信息的作用引入进了模型。 overly-specific noise 针对这个问题，作者提出了一种Hierarchcical Loss Normalization的损失函数，因为越细粒度的类别，他们所占的比重应该是不一样的，例如如果选择了athlete这个标签，那么较粗的粒度肯定要选择person，而不是location之类的，而传统的loss function在优化时，就是将他们平等对待的，因此作者希望损失函数能够更少的惩罚那么相关联的那些标签，即 $$p^{‘}(y|m,c) = p(y|m, c) + \beta\sum_{t\in\Gamma}p(t|m,c), \quad \tag{3}$$ 其中，$\Gamma$就是在类型路径上属于$y$的祖先节点，这样对类型进行分类处理，这样在最后的分类预测时就可以降低不同类别的噪声的影响了。 这就是这篇文章的大体框架，主要是在噪声处理上一些措施，感觉还是值得借鉴的 文章3这篇文章也是针对第一篇文章进行的一些改进，主要在以下的几个地方： context不再是独立处理 针对context的attention，要考虑到和entity mention之间的对齐关系 增加了文档级别的context 不再考虑人工特征，并通过实验证明人工特征加进去对模型的提升并不大 模型 从模型图里可以看出来整个模型的框架， entity encoder：相同的方法，首先embedding，然后进行进行平均，得到entity的表示 sentence-level context：就是entity所处的句子，将其通过一个L层Bi-LSTM，然后利用隐层状态和entity表示之间的dot product计算attention，最后对所有的隐层状态做加权，得到句子级别的context表示 document-level context：这部分相对简单一些，做着先使用了一个预训练好的模型（gensim.doc2vec）得到文档的表示，然后通过一个多层感知机，得到文档级别的context表示 拼接起来，得到输入的特征表示，在此基础上，将类别也进行embedding，最后通过一个逻辑回归得到该entity输入每个类别的概率， 这点独立写出来，算是作者的一个亮点，作者不是使用一个统一的阈值来决定eneity mention属于哪个类别，而是使用了 一种自适应的阈值，每个不同的类别都有一个属于自己的阈值，该阈值是通过模型学出来的，然后预测出来的概率只有超过该阈值才能说属于该类别。 分析作者对结果进行了一些分析，得到以下两点： 人工构建的特征作用并不大，可能是因为这些人工特征大多都是关于语法或者主题的一些信息，而这些信息都通过注意力机制和文档级别的context已经得到了，因此再补充这些信息的意义不大 对类别进行层次化编码的效果也很小，并做作者通过一些例子展示，说明entity mention是依赖情境的，属于不同粗粒度的类别可能由于情境的原因而被标记为entity mention的类别，也就是说类别的层次化信息其实意义不太大，（对这点我持保留态度） 总结从这三篇文章中基本上可以看到目前使用神经网络做NET的一些基本方法以及面对的一些问题，个人感觉可以从以下几点考虑新的方法： entity mention的表示 context的选择及表示 label的表示，包括噪声的处理，层次化信息的运用等， 目前基本上只想到这些，感觉从这个地方搞起来还是有很多可以做的东西，♪(＾∀＾●)ﾉ]]></content>
      <categories>
        <category>paper_reading</category>
      </categories>
      <tags>
        <tag>NET</tag>
        <tag>context， neural network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[What Value Do Explicit High Level Concepts Have in Vision to Language Problems?]]></title>
    <url>%2F2018%2F06%2F30%2F2018-06-30%2F</url>
    <content type="text"><![CDATA[Title: What Value Do Explicit High Level Concepts Have in Vision to Language Problems? Authors: Qi Wu, Chunhua Shen, Lingqiao Liu, Anthony Dick, Anton van den Hengel Link: https://arxiv.org/abs/1506.01144 背景Vision-to-Language(V2L)主要是研究图像和文本的联合建模，利用图像为文本提供丰富的辅助信息，利用文本为图像提供高层次的抽象信息。该主题有着越来越多的应用场景，例如Image Captioning，Visual Question Answering, Visual Dialog等等。目前常用的方法就是利用CNN来处理图像，利用RNN来处理文本，然后直接整合或者通过Attention Mechanism来整合。那么，这些方法是否真正理解了图像的意义，或者说利用CNN的方法是否真的获取到了图像的高层次的抽象信息。针对这个问题，本文在CNN-RNN的基础上提出了一种利用图像高层次语义的方法，并在多个任务上验证了其有效性。 模型框架首先展示模型的基本框架 从图中我们可以看出模型的大致结构 利用预训练的模型，经过transfer learning之后得到multi-label的模型结构，并将图像输入抽取到一个对应的属性向量 将得到的图像属性应用到不同的V2L任务当中去。 那么很重要一点就是如何将图像用一个属性向量表示，这部分，在本文中，作者称其为属性预测器，接下来就来详细了解一下这个属性预测器。 属性预测器（Attribute Predictor） 属性字典： 既然要使用高层次的抽象表示来表示图像的信息，那么最直接的方法就是和自然语言建立联系，因此作者首先建立了一个属性字典。为了保证得到的词和图像之间紧密相联，作者使用了image captioning中的图像和描述，然后抽取频率最高的c个词，为了保证效果同时降低属性字典的大小，该字典是时态，单复数不敏感的，也就是说“dogs”和“dog”是同一个属性，最后就建立了一个大小为256的字典。有了这个字典，就可以利用图像的描述将图像和属性字典联系起来了。 多标签分类： 为了将图像和属性联系起来，作者将这个问题看作是多标签分类问题，具体方法如下图： 从图中我们大致可以看清楚整个流程，作者使用了预训练好的VGG模型作为模型的初始化参数，然后在该模型方法image captioning数据集MS COCO上进行fine-tune，这一步，作者将最后一层改为一个c分类的模型，c就是属性字典的大小。在这里，作者使用了element-wise logistic loss function。也就是说在图像的描述中，如果存在某个属性$y_i \in c$，那这个$y_i=1$，否则$y_i = 0$，然后损失函数就可以写为 $$J = \frac{1}{N}\sum_{i=1}^{N}\sum_{j=1}^{c}log(1+exp(-y_{ij}p_{ij})), \quad \tag{1}$$ 在fine-tuning过程中，只有VGG的最后两个全连接层和模型的最后一层进行训练，其他层保持不变。 在此基础上，考虑到不同的属性关注的仅仅是图像中的某一个区域，因此作者首先使用了一种normalized cut的算法将图像切分为m个聚类，然后每个聚类中的图像块在区域划分算法中评分比较高的top-k会被挑选出来送给CNN，这个CNN就是上一个fine-tuning之后的结果。同时为了更好的表示图像，作者也将整幅图像送给该CNN，这样就有了mk+1属性表示向量，最后作者使用一个maxpooling操作，得到图像的最终属性表示向量$V_{att}(I)$。这个是一个十分重要的表示 语言模型这部分相对来说和一般的做法差别并不大，作者分别在Image captioning，VQA-single word和VQA-sentence三个任务上进行验证，首先看如何将这个属性向量插入 蓝色虚线是对比方法，红色实线是图像的属性向量，这个还好理解的。Image captioning模型中使用属性向量作为-1时刻的输入（并不是直接作为隐层状态的初始化，经过了一个线性变换）；VQA-Single-word任务中也是一样的操作；VQA-sentence任务中就是将其作为生成器的初始化输入。 这部分相对来说比较简单，个人感觉作者可能认为在图像处理阶段已经将图像使用高层次的抽象信息表示了，在这里就是自然语言了，有了这个中间桥梁，图像和对应的文本之间就更好关联起来了，因此一般都将其放到了语言模型的初始化部分。当然，也正是因为这样，语言模型处理的可以认为基本上都是文本信息，因此就会有比较好的表现效果。 实验结果照例还是直接上实验结果图： 作者使用的数据集主要是MS COCO，Flickr8k和Flickr30k，实验结果证实了作者的方法确实十分有效，作者也在VQA上进行了一些验证，这里就不再展示了。 总结传统的V2L任务中，大家一般都是利用预训练好的图像模型来抽取图像特征，然后将其应用到语言模型中，作者在这里给我们提供了一种新的思路，利用已有的信息，为图像和文本之间建立一个桥梁，这样直观的信息表示和抽象的信息表示能够更好的融合在一起，从而为更好的理解语义，理解图像提供支撑。我自己还有一个想法：目前使用的预训练模型一般都是在ImageNet上进行训练的，而ImageNet主要是一个分类图像数据集，因此这些模型抽取的特征可能更多的服务于分类任务，但将其利用到V2L时是不是就会有一些信息偏差呢，是不是利用比如说做目标检测的图像预训练模型会有不一样的效果呢？值得思考↖(^ω^)↗]]></content>
      <categories>
        <category>paper_reading</category>
      </categories>
      <tags>
        <tag>V2L</tag>
        <tag>Image Captioning</tag>
        <tag>Language Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Semantic Sentence Matching with Densely-connected Recurrent and Co-attentive Information]]></title>
    <url>%2F2018%2F06%2F30%2F2018-06-29%2F</url>
    <content type="text"><![CDATA[Title: Semantic Sentence Matching with Densely-connected Recurrent and Co-attentive Information Authors: Seonhoon Kim, Jin-Hyuk Hong, Inho Kang, Nojun Kwak Link: https://arxiv.org/abs/1805.11360 句子匹配（Sentence Matching）是自然语言理解任务中一个非常重要的任务，例如Natural Language Inference，Paraphrase Identification，Question Answering等都可以归属于这个任务。这个任务主要就是理解句子语义，理解句子之间的语义关系。因此如何去表示这些内容就变得十分重要了。为了更好的利用原始特征信息，作者参考DenseNet，提出了一种densely-connected co-attentive recurrent neural network模型，该模型最突出的地方就是可以从最底层到最顶层一直保留原始信息以及利用co-attention得到的交互信息。接下来，就对文章进行详细了解 模型结构首先是模型图： 不得不说，这个图还是很粗糙的，一点都不够精致，但模型的基本单元以及整体框架已经完全包含进去了，我们姑且用这个图对模型进行分析吧 输入层自然语言的任务首先就是输入层，对每个词的one-hot表示进行embedding， $$e_{pi}^{tr} = E^{tr}(p_i), \\ e_{pi}^{fix} = E^{fix}(p_i), \\ c_{p_i} = Char-Conv(p_i), \\ p_i^w = [e_{pi}^{tr}; e_{pi}^{fix}; c_{p_i}; f_{p_i}], \quad \tag{1}$$ 这几个公式很好理解，首先作者将词的embedding分为两部分，一部分参与训练，即$E^{tr}$，另一部分是固定不动的，即$E^{fix}$，然后就是词级别的表示char-Conv，以及一些exact match的匹配特征，主要是a中的每个词是否在b中有对应的词，然后将这些表示拼接起来，就得到了每个词的最后表示$p^w_i$。 密集连接层在这一层，作者收DenseNet启发，使用了密集连接和RNN结合的方法来实现对对句子的处理。首先$h_t^l$表示的是第l层的RNN的第t的隐层状态， $$h_t^l = H_l(x_t^l, h_{t-1}^l), \quad x_t^l = h_t^{l-1}, \quad \tag{2.1}$$ $$h_t^l = H_l(x_t^l, h_{t-1}^l), \quad x_t^l = h_t^{l-1} + x_t^{l-1}, \quad \tag{2.2}$$ $$h_t^l = H_l(x_t^l, h_{t-1}^l), \quad x_t^l = [h_t^{l-1}, x_t^{l-1}], \quad \tag{2.3}$$ 式2.1是传统的多层RNN的结构，前一层的RNN的 隐层状态作为当前层的输入，然后就是RNN的计算方式，式2.2借鉴了残差网络，当前层的输入不仅包含了前一层的隐层状态，同时包含了前一层的输入，但他们是相加的方式，作者认为这种相加的形式很可能会阻碍信息的流动，因此借鉴DenseNet，作者使用了拼接了方式，这样不仅保留了两部分信息，同时拼接方法也最大程度的保留了各自的独有信息。但这就有一个问题了，多层的RNN的参数就不一样了，因为拼接的方式导致了每一层输入对应的参数规模是在不断变大的，这样就不能做的很深了。 密集连接注意力因为句子匹配考虑的两个句子之间关系，因此需要建模两个句子之间的交互，目前来说，注意力机制是一种非常好的方法，因此作者在这样也使用了注意力机制， $$a_{p_i} = \sum_{j=1}^{J}\alpha_{i,j}h_{q_j}, \\ \alpha_{i,j} = \frac{exp(e_{i,j})}{\sum_{k=1}^Jexp(e_{i,k})}, \quad e_{i,j} = cos(h_{p_i}, h_{q_j}), \quad \tag{3.1}$$ 这个就是传统的co-attention计算方法，计算两个序列之间的在每个词上的对应关系，不过作者这里比较粗暴，直接使用了余弦相似度来计算每两个词之间的相似，这里也可以使用一个简单的MLP来计算。有意思的地方在下边 $$h_t^l = H_l(x_t^l, h_{t-1^l}), \quad x_t^l = [h_t^{l-1}, \alpha_t^{l-1}, x_t^{l-1}], \quad \tag{3.2}$$ 这个就很有意思了，我们传统的做法是得到每个词在对方句子上的概率分布之后，使用对方句子中每个词向量的加权和作为当前词的向量表示，而这里作者直接使用了计算出来的权值分布，将其作为一个特征引入到当前层的输入当中，这个感觉还是很有意思的。 瓶颈处理层正如前边提到的，这种dense连接方式直接导致的一个问题就是随着模型的加深，参数量会变的越来越多，这样最后全连接层的压力就会特别大。因此作者在这里使用了一个AutoEncoder来解决这个问题。AutoEncoder可以帮助压缩得到的巨大向量表示，同时可以保持原始的信息。这个操作还是很不错的。 分类层这是处理两个句子关系常用的一种匹配方法，作拼接，相减，点乘，不过作者在这里也是用了相减的绝对值，然后将最终拼接的向量通过一个全连接层，然后根据任务进行softmax分类，我个人做过实验，相减的效果要好于相减的绝对值，因为相减不仅可以表示差异，同时可以表明信息流方向，而相减的绝对值就更专注于差异了，两个都用应该是效果比只用一个好的。 实验结果照例，上图，作者在NLI任务和Question Pair两个任务上进行了模型验证，效果当然是十分不错的。 感想这篇文章主要集中在句子匹配任务上，将DenseNet的一些想法引入到了stack RNN中，还是可以给人一些灵感的，比如说从残差连接到DenseNet，比如说注意力权值的使用方法，比如说利用AutoEncoder来压缩向量，这些还是十分值得学习的。♪(＾∀＾●)ﾉ]]></content>
      <categories>
        <category>paper_reading</category>
      </categories>
      <tags>
        <tag>sentence matching</tag>
        <tag>NLI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neural Architectures for Fine-grained Entity Type Classification]]></title>
    <url>%2F2018%2F06%2F20%2F2018-06-20%2F</url>
    <content type="text"><![CDATA[Title: Neural Architectures for Fine-grained Entity Type Classification Author: Sonse Shimaoka, Pontus Stenetorp, Kentaro Inui, Sebastian Riedel Link: https://arxiv.org/pdf/1606.01341 包含文章 An Attentive Neural Architecture for Fine-grained Entity Type Classification Neural Architectures for Fine-grained Entity Type Classification 这两篇文章是同一组作者做的，相关内容也比较类似，因此放到一起进行介绍 问题定义问题Named Entity Typing (NET)主要是为实体表示（entity mention）标记其类别的一个任务，输入一般是一个句子，包含情境和实体表示，一般用$[C_{-s}, C_{-s+1}, …, C_{-1}][w_1, w_2, …, w_n][C_1, C_2, …, C_s]$表示，输出的结果就是实体表示的类别，和传统的分类任务不同的地方在于，实体表示有可能是属于多个类别的（如果分类粒度比较细的话），而且这些类别之间也存在包含关系之类的，这点就比较复杂了，目前比较常用的做法是首先根据输出概率，选择一个最大的作为entity mention的类别（保证至少有一个类别），然后设定阈值，大于阈值的都可以认为是该entity mention的类别。 评价标准一般使用以下三个作为实验效果的评价标准： strict $$Precision = Recall = \frac{1}{N}\sum_{i=1}^{N}\delta(\hat{T}_i = T_i), \quad \tag{0.1}$$ loose macro $$Precision = \frac{1}{N}\sum_{i=1}^N\frac{|\hat{T}_i\cap T_i|}{|\hat{T}_i|}, \quad \tag{0.2}$$ $$Recall = \frac{1}{N}\sum_{i=1}^N\frac{|\hat{T}_i\cap T_i|}{T_i}, \quad \tag{0.3}$$ loose micro $$Precision = \frac{\sum_{i=1}^N|\hat{T}_i \cap T_i|}{\sum_{i=1}^{N}|\hat{T}_i|}, \quad \tag{0.4}$$ $$ Recall= \frac{\sum_{i=1}^N|\hat{T}_i \cap T_i|}{\sum_{i=1}^{N}|T_i|}, \quad \tag{0.5}$$ 模型框架 该框架展示了基于神经网络的NET模型的基本结构，在本文中利用上图对该 框架进行简单介绍 Entity Mention表示首先得到每个词的词向量，将entity mention中的所有词向量做平均，得到entity mention的表示，考虑到entity mention一般不是很长，所以该方法简单有效，当然也可以使用RNN之类的方法进行表示， $$v_m = \frac{1}{M}\sum_{i=1}^Mu(m_i), \quad \tag{1}$$ 其中，u就是将每个词表示为它的词向量表示。 context表示很容易理解，entity mention的语义是十分依赖其所存在的情境的，如果是在一个句子中的话，那么该情境信息就是上下文的词，在本文中，作者通过三种方法来处理这些词： 和entity mention表示类似，采用和平均的方法 $$v_c = \frac{1}{C}\sum_{i=1}^{C}[u(l_i), u(r_i)], \quad \tag{2.1}$$ 考虑到情境信息是一个序列关系，因此也可以采用LSTM来处理 $$h_i, s_i = lstm(u_i, h_{i-1}, s_{i-1}), \\ v_c = [\overrightarrow{h_C^l}, \overleftarrow{h_1^r}] \quad \tag{2.2}$$ 单纯那最后一个状态进行拼接并不能有效利用LSTM中的信息，因此注意力机制派上了用场，这里采用了得是一种类似于self-attention的方法： $$e_i^l = tanh(W_e[\overrightarrow{h_i^l}, \overleftarrow{h_i^l}]), \quad \tag{2.31}$$ $$\widetilde{a}_i^l = exp(W_ae_i^l) , \quad \tag{2.32} $$ $$ a_i^l = softmax(\widetilde{a}_i^l) \quad \tag{2.33}$$ $$v_c = \sum_{i=1}^{C}a_i^l[\overrightarrow{h_i^l}, \overleftarrow{h_i^l}] + a_i^r[\overrightarrow{h_i^r}, \overleftarrow{h_i^r}], \quad \tag{2.34}$$ 从这里我们可以看出是由各自的输入决定各自的权重，但在最后计算整体的权重正规化时同时考虑了左侧和右侧的权重，在这里将这两部分同时考虑，最后得到一个加权和作为最后的context表示。 分类分别得到entity mention和context的表示之后，普遍的做法是直接将这两部分拼接起来，然后进行逻辑回归， $$y = \frac{1}{1 + exp(-W_y[v_m, v_c])}, \quad \tag{3.1}$$ 有了预测结果，考虑到这是一个分类任务，那么就可以使用交叉熵作为损失函数， $$L(y, t) = \sum_{k=1}^K-t_klog(y_k) - (1-t_k)log(1-y_k), \quad \tag{3.2}$$ 在这个损失函数中，K表示所有的类别数，t是预测出来的二值向量，即在每个类别上都要做一个二分类，根据之前的介绍，这部分需要这么做，因为他的分类结果是不一定的。 这就是基于神经网络的NET模型的大体框架，从我看到的几篇文章中，基本上都是用了这样的框架，只是在处理细节上略有不同， 额外部分本文题目的这篇文章可以认为是作者对前一篇工作的改进，具体改进部分有两点： 人工特征信息考虑到有些人工特征信息是十分重要的 ，但如果直接让模型去学习，需要花费很大的精力，现在整个神经网络结构也趋向于加入一些简单的人工特征信息，本文也是考虑到这些信息，具体如下图： 这些特征基本上将entity mention的一些语义信息，主题信息等考虑了进去，相当于增加了很多先验知识，这个还是十分有用的，那如何加这些信息呢？作者首先用0，1向量表示这些特征信息，然后将其映射到低维空间，最后得到人工特征的向量表示 $$v_f = W_ff(m). \quad \tag{4.1}$$ 然后将其加入到公式(3.1)中的拼接向量，变为如下形式： $$y = \frac{1}{1 + exp(-W_y[v_m, v_c, v_f])}, \quad \tag{4.2}$$ 这个还是很有特点的，一般我们都是将这些特征信息加入到最初的输入中，这样丰富了输入的信息，整个模型也可以更好地利用这些信息，这个方法个人感觉这些特征信息利用的不够充分。 分层标签编码这是本文另一个很有意思的地方，首先，作为分类目标，其实考虑到他的类别表示，也是可以使用词向量进行编码的，而且这么做有一个好处，一些不常见的标签可以通过这种方式找到离他比较近的语义空间向量，从而能够更准确的进行分类，作者也是考虑到这样的信息，同时分类内容比较细的话，标签信息之间具有包含关系，因此，作者使用0，1向量表示类别信息，同时包含high-level和low-level的标签，然后对它们进行混合编码，而不是每个类别一个向量表示，具体可以从下图感受： 然后就得到了类别表示矩阵$W_y$，巧妙地地方在于，作者使用这个矩阵表示作为公式（4.2）分类层的参数，从而很好的将类别信息引入到了分类过程中，这样模型在分类的的时候就能获取更多的信息了，这个信息融合方式还是很有意思的。 实验结果照例贴出最后的结果图，作者的方法虽然简单，但还是很有效的 个人总结这篇文章展示了基于神经网络的NET模型的基本结构，包括对context的处理，对entity mention的处理，attention的使用，人工特征的添加等，是一篇很不错的文章，同时该方法也有很多地方值得改进，例如人工信息的利用，注意力机制，对文本信息的处理等，感觉还是有很多地方可以改进的，值得思考↖(^ω^)↗]]></content>
      <categories>
        <category>paper_reading</category>
      </categories>
      <tags>
        <tag>NET</tag>
        <tag>representation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neural Network Models for Paraphrase Identification, Semantic Textual Similarity, Natural Language Inference, and Question Answering]]></title>
    <url>%2F2018%2F06%2F17%2Fpaper-reproduction%2F</url>
    <content type="text"><![CDATA[Title: Neural Network Models for Paraphrase Identification, Semantic Textual Similarity, Natural Language Inference, and Question Answering Author: Wuwei Lan, Wei Xu Link: https://arxiv.org/pdf/1806.04330 介绍这篇文章是COLING 2018的beat reproduction paper，文章主要对现有的做句子对任务的最好的几个模型进行了重现，并且作者实现出来的效果和原文章声称的效果相差不多，这点还是很厉害的，而且作者对语义理解的集中任务也做了相关梳理，文章简单易读，还是很值得一看的。 任务句子对建模是NLP，NLU中比较基础，并扮演着重要角色的任务，主要集中在语义理解，语义交互上，也是我自己的一个研究方向，大致有这几类任务 Semantic Textual Similarity (STS) ：判断两个句子的语义相似程度（measureing the degree of equivalence in the underlying semantics of paired snippets of text） Natural Language Inference (NLI) ：也叫Recognizing Textual Entailment(RTE)，判断两个句子在语义上是否存在推断关系，相对任务一更复杂一些，不仅仅是考虑相似，而且也考虑了推理。 Paraphrase Identification (PI) ：判断两个句子是否表达同样的意思（identifing whether two sentences express the same meaning） Question Answering (QA) ：主要是指选择出来最符合问题的答案，是在给定的答案中进行选择，而不是生成 Machine Comprehension (MC) ：判断一个句子和一个段落之间的关系，从大段落中找出存在答案的小段落，对比的两个内容更加复杂一些。 模型有了任务，作者选取了集中目前情况下最好的模型，因为原文中每个模型可能只针对了某些任务进行了很多优化，那这些模型是否真的有效呢，作者考虑这些模型在所有的任务上进行比较，在介绍模型之前，作者首先介绍了句子对建模的一般框架： 一般框架 输入层：适用预训练或者参与训练的词向量对输入中的每个词进行向量表示，比较有名的Word2Vec，GloVe，也可以使用子序列的方法，例如character-level embedding 情境编码层：将句子所处的情境信息编码表示，从而更好的理解目标句子的语义，常用的例如CNN, HighWay Network等，如果是句子语义表示的方法，一般到这里就结束了，接下来会根据具体的任务直接使用这一层得到语义表示 交互和注意力层：该层是可选的，句子语义表示有时候也会用到，但更多的是词匹配方法用到的，通过注意力机制建模两个句子在词层面的匹配对齐关系，从而在更细粒度上进行句子对建模，个人认为句子语义表示也会用到这些，只是句子语义表示最后会得到一个语义表示的向量，而词匹配的方法不一定得到句子语义的向量 输出分类层：根据不同的任务，使用CNN，LSTM，MLP等进行分类判断。 下图展示了一些句子语义表示的模型的基本框架： 有了这个一般的框架，接下来作者选取了集中目前最好的模型进行重现 模型选择 InferSent[1]：BiLSTM+max-pooling SSE[2]：如图1，和InferSent比较类似 DecAtt[3]：词匹配模型的代表，利用注意力机制得到句子1中的每个词和句子2中的所有词的紧密程度，然后用句子2中的所有词的隐层状态，做加权和表示句子1中的每个词 ESIM[4]：考虑了一些词本身的特征信息，和DecAtt比较类似 PWIM[5]：在得到每个词的隐层状态之后，通过不同的相似度计算方法得到词对之间相似关系，最后利用CNN进行分类。 数据：为了更好的展示每个数据的情况，在这里直接用下图展示作者使用到的数据集： 结果直接上结果，上图是原文章中的结果，下图是作者重现的结果 从结果上看，作者实现的效果还是很厉害的，基本上跟原文章声明的不相上下，当然由于不是针对特定任务进行特别优化，所有效果还是有一点点差的，但基本上可以认为是实现了原来的效果，而且作者也发现了一些有意思的现象，例如：表现最好的就是ESIM，个人感觉这里面加入了很多次本身的一些信息，例如近义词，反义词，上下位信息等，这些信息其实对句子语义理解十分重要。 以上就是这篇文章的整体介绍，作者完整实现了这些方法，并在不同的数据集上进行验证，工作量还是很大的，而且对句子对建模进行了比较完整的介绍，还是很有意思的。♪(＾∀＾●)ﾉ 引用[1]：Supervised learning of universal sentence representations from natural language inference data [2]：Shortcut-stacked sentence encoders for multi-domain inference [3]：A decomposable attention model for natural language inference [4]：Enhanced LSTM for natural language inference [5]：Pairwise word interaction modeling with deep neural networks for semantic similarity measurement]]></content>
      <categories>
        <category>paper_reading</category>
      </categories>
      <tags>
        <tag>natural language inference</tag>
        <tag>natural language understanding</tag>
        <tag>semantic similarity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Improving Neural Fine-Grained Entity Typing with Knowledge Attention]]></title>
    <url>%2F2018%2F06%2F17%2Fpaper-NET%2F</url>
    <content type="text"><![CDATA[Title: Improving Neural Fine-Grained Entity Typing with Knowledge Attention Author: Ji Xin, Yankai Lin, Zhiyuan Liu, Maosong Sun Link: http://nlp.csai.tsinghua.edu.cn/~lzy/publications/aaai2018_entitytyping.pdf 任务本文针对的是Named Entity Typing(NET)任务，该任务主要是判断一个实体表示(entity mention)的类别，粒度的分类可以分为：person, location, organization，others。细粒度的分类根据不同的数据有着不同的分类情况，例如：FIGER dataset 有112类；也可以根据需要自定义类别个数进行分类，例如：从DBpedia中抽取22类。 该任务也是一个比较基础的任务，可以为问答，对话，语义理解等提供一些辅助理解的信息，而且和语义理解类似，同一个实体表示在不同的情境(context)下的类别是不一样，同样需要考虑情境信息。 现状传统的方法大多集中在特征抽取，例如选取多种特征抽取的方法，例如pattern-based extractor，Knowledge base，mention-based extractor等，利用这些不同的方法得到实体表示的不同类别候选，然后利用词义消歧（word sense disambiguation ）的方法选择最合适的类别。这里边最受关注的地方在于知识图谱的运用，知识图谱将很多先验知识及关系整合到图中，尤其是NET中的细粒度分类， 单纯利用神经网络来做是不行的，很多类别的样本都很少，而知识图谱可以提供必要的帮助。 神经网络的方法目前也慢慢多起来，神经网络在提取特征阶段已经被证明非常有效，因此在该任务上神经网络+知识图谱应该是一种非常有效的方法，而本文就是这样的一种方法。 模型 模型整体看起来是比较简单的，而本文主要是为了解决NET中的两个问题： 在实体表示分类时需要考虑其所存在的情境，而这点是被忽略的； 虽然知识图谱已经很早就被用到了NET中，但是知识图谱中实体之间的关系，并没有得到很好的利用。 因此，作者提出了如上的模型，具体如下： 首先适用预训练的模型对所有的词进行标识 ，得到每个词的词向量， 实体表示的向量表达考虑到实体表示的短语是比较短的，大多是都是一个或者两个词，因此直接将每个词的向量相加，取均值，得到实体表示的向量表达： $$m = \frac{1}{n_m}\sum_{i=1}^{n_m}m_i \quad \tag{1}$$ 情境信息的表示为了更好的表示中心词的情境，例如中心词所存在的句子，作者使用BiLSTM分别整合左边和右边的情境信息，并利用注意力机制整合他们在LSTM中的隐层状态，最后整合为一个情境表示向量： $$c = \frac{\sum_{i=1}^{L}(a_i^l[\overrightarrow{h_i^l}, \overleftarrow{h_i^l}]+a_i^r[\overrightarrow{h_i^r}, \overleftarrow{h_i^r}]) }{\sum_{i=1}^{L}a_i^l+a_i^r} \quad \tag{2}$$ 这个公式还是很好理解的，将每个状态的两个方向表示拼接起来，乘以对应的权重，然后做加权和，最后再做平均，就得到了情境信息的向量表示，那么接下来就是如何表示情境信息的权重了。 注意力机制在这里作者考虑了很多不同的注意力机制， 语义注意力机制，就是考虑情境信息的权重，由自身的语义信息来计算所占的比重，类似于self-attention： $$a_i^{SA} = \sigma(W_{s1}tanh(W_{s2}[\overrightarrow{h}_i, \overleftarrow{h}_i])). \quad \tag{3.1}$$ 因为我们需要考虑的是实体表示的类别，那么也可以计算实体表示所关注的重点在什么地方，也就是基础版的attention： $$a_i^{MA} = \sigma(mtanh(W_{MA}[\overrightarrow{h}_i, \overleftarrow{h}_i])). \quad \tag{3.2}$$ 正如之前问题里提到的那样，知识图谱不仅包含了实体，同时还有实体之间的关系信息，这点也是十分重要的，因此作者使用了知识图谱中表示关系的方法TransE来处理知识图谱中的关系表示，并将其应用到注意力机制中： $$a_i^{KA} = \sigma(etanh(W_{KA}[\overrightarrow{h}_i, \overleftarrow{h}_i])), \quad \tag{3.3}$$ 这其中$e$就是实体的embedding表示， 类别预测有了实体表示的向量和情境信息的向量，最后就是一个分类了，作者将得到的两个向量表示拼接起来，然后通过一个两层的MLP进行分类，得到最后的结果： $$y = \sigma(W_{y1}tanh(W_{y2}[m, c])), \quad \tag{4}$$ 最后使用二分类的交叉熵作为损失函数，因为每一个实体表示的类别可能不止一个，这可能是一个多分类问题，因此作者在每个类别上都是用了二分类的交叉熵，最后将所有的全都加起来作为最终的损失函数。 实验结果照例，还是贴一个最后的结果图，因为使用了神经网络将情境信息融入到了实体分类中，可以更好地分类出在特定情境下的类别，也就更符合实际情况，从而获得更好的效果，当然将知识图谱中的关系信息也考虑进去也是本文的另一个创新点，这点还是很有意思的。 个人评价这是我接触NET之后读的第一篇利用神经网络来做的方法，对比那些利用不同的特征抽取方法来对实体表示进行分类，神经网络在抽取特征方面确实是省了不少的力气，而且整个模型简单有效，这就是一种非常好的方法。当然，该方法相对来说还是比较简单的，例如在情境信息的表示，情境信息和知识图谱的融合，相互辅助等方面还有很多可以做的，而且这个问题对语义理解也是一个很重要的方面，很值得学习研究。 以上就是这篇文章的整体介绍，NET还是很有意思的，搞起来搞起来♪(＾∀＾●)ﾉ]]></content>
      <categories>
        <category>paper_reading</category>
      </categories>
      <tags>
        <tag>NET</tag>
        <tag>KB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sentence Modeling via Multiple Word Embeddings and Multi-level Comparison for Semantic Textual Similarity]]></title>
    <url>%2F2018%2F06%2F07%2Fpaper-20180607%2F</url>
    <content type="text"><![CDATA[这篇文章主要是集中在对词的多方面语义表示，在此基础上实现对句子语义的准确理解，并在多个句子语义理解相关任务上取得了不错的表现。 Different word embedding models capture different aspects of linguistic properities. 模型结构不同的词向量模型获取的是不同的语义信息，例如：BOW的上下文反映的是词的domain信息（scientist and research），基于解释关系的上下文反映的是词的语义相似度信息（boy and kid），因此作者提出来通过选取不同的上下文来获取词在不同方面的语义信息，具体作者选了 word2vec：在Google News上进行训练的 fastText：在wikipedia上训练的 GloVe：选择的是300d的词向量，训练数据为Common Crawl Baroni：使用的是context-predict的方法，使用的训练数据为English Wikipedia+British National Corpus SL999：使用的训练数据为paraphrase database PPDB，然后再SimLex-999上微调 以下是模型的整体框架图： 输入处理作者使用K个预训练的词向量表示每个词，然后将这些结果拼接起来，作为每个词的最终表示 $$e_w^{concat} = e_w^1\oplus e_w^2 \oplus … \oplus e_w^K \tag{1}$$ 卷积网络为了学习到一个可以表示每个词的multi-aspect的语义，作者使用了一个卷积网络的结构，有H个卷积核，每个卷积核可以通过一个线性变换表示，具体如下： $$e_w^{r_i} = \sigma(e_w^{concat}r_i^T + b_{r_i}) \\ e_w^{multi} = [e_w^{r_1}, e_w^{r_2}, … , e_w^{r_H}] \tag{2}$$ 句子建模使用卷积网络的好处是参数共享，可以学习到局部特征，但是卷积神经网络有一个问题，在处理序列数据的时候容易丢失序列信息，因此作者在这里使用了LSTM来处理，从而保证了序列信息的保留，具体如下，作者首先在句子中所有词的相同纬度上进行max-pooling，获取到最有价值的信息，同时通过LSTM实现对整个句子的建模，然后选取最后一个状态作为句子的语义向量表示，最后将max-pooling的结果和LSTM的最后一个状态进行拼接，从而得到句子的语义表示，具体如下： $$e_s^{max}[i] = max(e_{w_1}^{multi}[i], e_{w_2}^{multi}[i], …, e_{w_n}^{multi}[i]) \\ e_s^{lstm} = LSTM(e_w^{multi})[-1] \\ e_s = e_s^{max} \oplus e_s^{lstm} \tag{3}$$ 多尺度比较有了每个句子的语义表示，根据任务的不同，就可以进行比较了，作者在这里选取了三种比较方式 word-word similarity： $$A_{ij} = \frac{s_1^{multi}[i] \cdot s_2^{multi}[j]}{\left|s_1^{multi}[i]\right|\left|s_2^{multi}[j]\right|} \\ sim^{word} = \sigma(W^{word}g(A)+b^{word})\tag{4}$$ 这个公式中，g表示的是讲一个矩阵展平为向量的函数，这是词与词之间的相似度比较 sentence-sentence comparison: Cosine Similarity: $$d_{cosine}=\frac{e_{s_1}\cdot e_{s_2}}{\left|e_{s_1}\right|\left|e_{s_2}\right|} \tag{5.1}$$ Multiplication vector &amp; Absolute difference: $$d_{mul}=e_{s_1}\odot e_{s_2} \\ d_{abs} = |e_{s_1} - e_{s_2}| \tag{5.2}$$ Neural difference: $$x = e_{s_1}\oplus e_{s_2} \\ d_{neu} = W^{neu}x + b^{neu} \tag{5.3}$$ 最后将这些不同的结果拼接起来，做一个线性变换 $$d^{sent} = d_{cosine}\oplus d_{mul}\oplus d_{abs} \oplus d_{neu} \\ sim^{sent} = \sigma(W^{sent}d^{sent} + b^{sent}) \tag{5.4}$$ word-sentence comparison: 在这部分就是让句子1的语义表示和句子2的每个词的语义表示进行比较，然后将比较结果矩阵展平，通过线性变化，得到这一阶段的相似度值 $$e_{s_1}^{ws}[i] = e_{s_1} \oplus s_2^{multi}[i] \\ sim_{s_1}^{ws}[i] = \sigma(W^{ws}e_{s_1}^{ws}[i]+b^{ws}) \\ sim^{ws}=\sigma(W^{ws^{‘}}[g(sim_{s_1}^{ws})\oplus g(sim_{s_2}^{ws})] + b^{ws^{‘}}) \tag{6}$$ 最后进行分类在这一阶段，作者将三种不同的相似度信息进行拼接，然后通过线性变换，最后softmax进行分类 $$sim = sim^{word} \oplus sim^{sent} \oplus sim^{ws} \\ h_s = \sigma(W^{l1}sim+b^{l1}) \\ \hat{y} = softmax(w^{l2}h_s+b^{l2}) \tag{7}$$ 最后的输出根据不同任务的不同有不同的修改。以上就是整个模型的过程。 任务作者是在比较两个句子之间的相似度，因此作者在不同的几个任务上进行了比较，分别是1）RTE: SICK数据集；2）STS：STSB和SICK数据集，这部分需要吐槽的一点是在RTE任务上居然没有使用SNLI这个大规模数据集，可能是效果表现不好，个人感觉 效果这里就贴一张结果图来展示作者实验的效果吧 个人评价首先作者的这个idea还是很有意思的，我在16年的一篇工作也使用了同样的一个idea，基本的motivation也是相同的，只是他在多个不同的任务上进行验证，同时将多方面的词表示扩展到了句子的语义表示上，我那个工作只是在词级别上的一个分析，同时只考虑了Recognizing lexical entailment这个任务，这点是我的不足。但这篇文章在句子语义建模上有些简单，因此个人感觉他的句子语义表示向量的效果可能不是很好，但作者在最后的相似度上考虑了词对词，词对句子，句子对句子三个方面，这个还是很有意思的，这点值得学习一下，考虑多方面语义时不仅要考虑输入上的多方面，在比较上也可以进行多方面的比较。 以上就是这篇文章的整体介绍，介绍完感觉有必要介绍一下我自己的工作，下次介绍♪(＾∀＾●)ﾉ]]></content>
      <categories>
        <category>paper_reading</category>
      </categories>
      <tags>
        <tag>word semantic</tag>
        <tag>natural language understanding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文投稿有感]]></title>
    <url>%2F2018%2F06%2F06%2FAfter-Writing%2F</url>
    <content type="text"><![CDATA[刚刚忙完了论文的投稿，虽说也写了几篇文章，但是进入依然十分缓慢，这次记录下自己在这次投稿过程中的感想，与君共勉 Title标题是整篇文章的开头，一定要清晰直接的介绍出自己的工作的卖点，不能使用那些会造成误解的词，否则开头就容易把人带偏，就像我这次，开始使用的是Hierarchical，后来改成了Multi-Level，虽然前者也有后者的意思，但是前者更偏向于树形结构，有等级从属关系，这样就容易给人造成误解， 所以起一个好的名字是十分有必要的。 Abstract摘要是一篇文章最精炼的部分了，从我的感觉来看，可以分成以下的形式： 第一句话：介绍要研究的问题 第二句话：当前工作有什么难题 第三句话：我们提出了什么方法，直接点明 第四句话：我们方法的卖点 第五句话：效果是怎么样的，如果有具体数据支撑就更好了 基本上可以用这些来表示，需要注意的是在这里提出的问题，突出的卖点是整篇文章的核心，在之后的部分都要有具体的支撑。摘要部分是最精炼的部分，也展示了文章最突出的地方，能让读者看了之后就明白作者的想法。 Introduction这部分我先举一个我在整个文章过程中的修改历程： 介绍问题-&gt;当前的研究现状-&gt;问题1，我们需要怎么做-&gt;正好有一些别的任务证明这么做是有效的-&gt;问题2，我们需要怎么做-&gt;总结，提出我们的方法，简单介绍-&gt;写贡献点 介绍问题-&gt;分类介绍当前研究现状及特点-&gt;存在的问题2，我们应该怎么做-&gt;问题1，我们应该怎么做-&gt;正好有一些别的任务证明这么做有效&gt;总结，提出我们的方法，简单介绍-&gt;写贡献点 介绍问题-&gt;分类介绍当前研究现状及特点-&gt;问题1，我们需要怎么做-&gt;当我们这么做时又会碰到什么问题-&gt;问题2，需要解决-&gt;基于以上观点，提出我们的方法，简单介绍-&gt;写贡献点 以上就是我在introduction上的大版本修改过程，因为我最初想突出了两个贡献点，而这两个贡献点彼此相差比较大，强硬写到一起，只会逻辑不通，读者也不知道你要表达什么，因此，突出一个重点，围绕这个重点写，所有的工作都是围绕这个重点展开的，这样就会十分清晰，也就容易看懂了。 Related-Work这部分好写，只需要将相关的工作做一介绍，整合他们的特点，指出他们存在的不足即可，需要注意的是相关工作一定要全面，不能丢三落四，否则很容易体现出你的相关调研做的不充分。 但这部分也很难写，如何使用简短的语句将当前的研究现状做一梳理，整合他们的特点，在此基础上提出新的论点，这点其实是非常考验作者功力的，我也在朝这个方向努力中。 还有需要强调一点的，这部分最好全都用一般过去时 Problem Statement &amp; Technical Details首先是问题形式化，这部分相对简单，但要注意符号的运用；同时可以在这里指出在问题中我们要解决什么问题，这个问题和我们的卖点是对应的，这样可以告诉读者，接下来需要注意那些地方，读者也能有重点的看这部分。 接着是技术部分，几点经验教训吧： 符号的定义，最好可以定义一个符号表，保证符号使用规范以及不出错，相关规范可以参考Ian Goodfellow的《深度学习》这本书，同时要注意符号要前后照应，和模型图对应，和各种分析对应；如果使用latex的话，可以定义一个newcommand，这样在后续修改过程中只需要改动这个地方就可以了 ，类似于程序中的头文件。 不能像实验报告那样，只写我们做了什么，我们怎么做，这是绝对不行的，这个也是我要注意的问题 不能像技术文档那样，事无巨细，每一条都有解释，有引文，这样就太啰嗦了，也是不行的 技术部分要详略得当，一些众所周知的内容，可以简单写，涉及到自己工作卖点的部分，一定要清晰解释，为什么要这么做，这么做有什么好处，这么做可以达到一个什么样的效果，然后是具体的做法，这点非常非常重要。 写公式的时候最好可以按照数学的方式写，作为一个计算机专业的学生，有时候写着写着就习惯于按照写程序的方式来写了，须知在程序中的相乘方式和在数学公式中是不一样的，这点需要十分注意。 模型图也要根据自己的卖点突出相应的重点，可以让读者不用看文字就能知道大致的重点是什么，要突出的地方要重点展示出来，同时图中的符号要与文字部分保持一致，保证能够彼此印证，最后图要画的美观大方，不能太繁琐，太复杂。 Experiment这部分我感觉是我的薄弱部分，因为有的时候不知道要做哪些实验来验证，写一个大致的想法吧，首先肯定是当前任务上的整体效果，这点一定要好，否则你就无法体现你模型的贡献了，在这部分，要注意baseline的选择，能够体现出自己工作的特点，同时能够展现当前的state-of-the-art效果，baseline的选择也是一门艺术。其次对自己模型的分析 ，既然提出了某个点十分重要，那肯定需要通过实验来验证它的重要性，并于之前的部分相呼应，因此ablation performance就十分有必要了。接着就是一些参数敏感性实验之类的，总之这部分要十分充实。同时在图标上，表格，折线图，柱状图，饼图等多样化来展现模型的特点，同时也体现出专业性。另外，如果可以做一个case study的话，最好做一个，这样可以更直观的体现出模型的卖点。 也有一点需要强调的，方便书写，这部分用一般现在时会好一些。 Conclusion最后这部分我一般都是做一简单总结，以及对未来工作的一些简单想法，目前还没有学习到好的conclusion写法，还在努力学习中。 还有就是一些小问题了，例如语法，时态，拼写等，这些会经常出现在文章中，因此仔细写，多检查，细心一些是十分有必要的。 以上，就是此次投文章的一些经验总结，希望下次能写出更好的文章出来，↖(^ω^)↗]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>paper-writing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自然语言推理介绍]]></title>
    <url>%2F2018%2F05%2F28%2FNLI-introduce%2F</url>
    <content type="text"><![CDATA[自然语言推理作为自然语言理解的一个重要组成部分，在整个自然语言理解中扮演着重要的角色，接下里我将对自然语言推理的现状做一简单总结，以下内容是我的小组分享的记录版。 自然语言推理简介 自然语言推理主要是判断两个句子（Premise, Hypothesis）或者两个词之间的语义关系，为了保证模型能够集中在语义理解上，该任务最终退化为一个分类任务，目前类别主要是三分类（Entailment，Contradiction，Neutral）。目前对这三类有各种各样的定义，但是我认为这三类的分类依据还是要落在语义理解上，通过语义关系来确定类别。 那为什么要研究自然语言推理呢？简单来讲，机器学习的整个系统可以分为两块，输入，输出。输入要求我们能够输入一个机器能理解的东西，并且能够很好的表现出数据的特点，输出就是根据需要，生成我们需要的结果。也可以说整个机器学习可以分为Input Representation和Output Generation。因此，如何全面的表示输入就变得非常重要了。而自然语言推理是一个分类任务，使用准确率就可以客观有效的评价模型的好坏；这样我们就可以专注于语义理解和语义表示。并且如果这部分做得好的话，例如可以生成很好的句子表示的向量，那么我们就可以将这部分成果轻易迁移到其他任务中，例如对话，问答等。这一切都说明了研究自然语言推理是一个非常重要但是非常有意义的事情。 以下是自然语言推理推理的发展历程 相关数据上一部分对自然语言推理进行了一个大致的介绍。众所周知，数据对模型非常重要，而且深度神经网络也是高度依赖数据的，那么我们来对目前的数据进行一个简单的梳理 这是自然语言推理领域一个非常重要的数据集，相关信息如上图所示，斯坦福大学通过众包的方式生成了这个自然语言推理领域第一个大规模人工标注的数据集，从此自然语言推理进入深度学习时代。 这个数据集和SNLI比较类似，但是它的前提句子来自真实场景的数据，因此在数据上更贴近现实一些，同时，每一条数据包含了类别信息。 这个数据集就更加贴近现实了，前提句和假设句全都来自真实场景，人工的作用放到了对每一条数据打标签，因此数据本身的人工影响就变小了。但是该数据全部来自科学问答，因此在类别上可能略显单一。 该数据集和前边不同的地方在于它是四个前提句对应一个假设句，这样在进行推理分类时，不仅需要考虑前提句和假设句的关系，还需要考虑前提句之间的相关关系，因此推理难度更大，但是这些文本句子全都来自image captioning工作，文本本身人工较少，因此文本质量上可能不如前者。但这也是一个很有意思的方向。 当然，还有很多其他的数据集，例如SICK, Add-one RTE, JOCI等，都是从不同角度对语义理解提出了一个要求。可以说自然语言推理领域目前正是百花齐放，十分繁荣。 一些方法词级别的推理 该方法主要研究的是词级别的推理。有研究表明，词具有不同方面的语义信息，例如book在名词角度可以表示为：书，但在动词角度可以表示为：预定；因此使用单一的向量可能无法有效区分这些内容，因此作者提出利用不同的上下文来获取词在不同角度的语义信息，例如：选取中心词周围的名词来表示它的topic信息，选取中心词周围的动词来表示它的function信息。这样对每个词就都有不同的语义向量表示，然后通过网络结构对相关信息进行拼接，最后考虑到不同的推理关系可能需要的信息时不同的，例如：上下位关系：狗-动物，可能需要的是topic相关的信息，因果关系：攻击-受伤，可能需要的更多的是function的信息，因此作者通过一个门结构计算出每种语义表示对推理关系的影响程度，然后进行加权求和，最后进行分类。并且该方法的可扩展性非常好，从网络结构上看，我们可以增加不同的语义表示，模型的结构和参数规模并不会有太大的提升，这也可以认为是模型的一个优点。 句子级别的推理句子级别的推理可以分为两部分，基于句子语义编码的方法和基于词匹配的方法，前者是首先将一个句子编码为向量，然后分析两个向量之间的关系；后者考虑更多的是词之间的匹配关系，不一定有句子的语义向量表示。 句子语义编码方法 该方法就是句子编码的方法，首先左图展现了这类方法的一般结构，首先通过不同的方法得到每个句子的语义向量表示；在此基础上，对两个向量作拼接，相减，点乘来得到两个语义向量之间的关系，最后通过一个MLP进行分类，右图就是句子编码部分可以采用的方法，例如：通过双向LSTM，得到隐层状态，对隐层状态做max-pooling或者做attention，得到的加权表示就只句子的语义向量表示，最右边的图示利用了CNN的结构，我们都知道CNN是建立输入之间的局部关系，那么作者使用了多层的CNN，通过多层卷积，底层获取的是local部分的信息，那么越往上就可以得到更长范围内的信息，从而对句子语义进行建模，这也是一种很不错的方法。 这个方法是对注意力机制（Attention Mechanism）的一种有效利用，我们可以清晰看出来，作者先对BiLSTM的隐层状态进行mean pooling，在此基础上，利用注意力机制得到句子中那些词对语义表示比较重要，然后对隐层状态进行加权求和，就得到了句子表示的向量，最后就是常用的框架。从该方法中我们也可以看到句子编码模型的基本结构。 词匹配方法 该方法是词匹配方法的一个代表工作，首先作者使用两个LSTM来处理两个句子，并且后一个LSTM的隐层使用前一个LSTM的最后一个状态初始化，在此基础上，作者在求后一个句子的隐层状态时，使用注意力机制考虑前提句子的每一个词的隐层状态，建立词之间的匹配关系，最后利用最后一个隐层状态作为最后分类的依据，在这个方法中我们看到，其实并没有句子语义向量的表示。 该方法在词匹配上进行了更深入的研究，不仅仅是计算他们的匹配程度，而是先求前提句中的每个词和假设句中的所有词之间的attention，并使用假设句中所有词乘以attention分布，来表示前提句中的每个词，这样就使用了对方的语义来表示自己，假设句也是一样。然后将得到的结果和原始的表示作拼接，通过变换，最后求一个和，得到句子的表示进行分类，该方法也是目前比较流行的方法，通过使用对方的语义来表示自己，从而对语义关系进行更好的建模。 问题Accuracy 这是第一个也是很重要的问题，目前在SNLI数据集上，最好的结果已经做到89.3%，那么接下来如何提升准确率呢？这是一个值得思考的问题。 Lexical Knowledge 这个问题很有意思，从数据上考虑，他只是修改了前提句中的一个词得到假设句，对于我们人类来说，进行这样的区分十分容易，但是由于两个句子之间的词的高重合度，模型可能会认为这两个输入是一致的，尤其是不同的两个词属于同一类的时候，他们的词向量表示会更相似。如果数据中有这样的例子，那模型肯定没问题，但如果训练数据中没有这样的例子，但实际上如果模型能够很好地理解语义，这个应该不是问题，而事实上这对模型来说是一个巨大的问题，对于这些词级别的不同，模型该如何去衡量呢？ Annotation Artifacts 这也是一个很有意思的问题，如前边所介绍的，数据集都是使用了人工，尤其是有一些数据集的假设句子全都是人写的，理论上来说人写的句子肯定比模型生成的好，但是人写的句子也有一些特点，例如推理关系是Entailment的时候，可能假设句的一些名词是前提句的上位词（woman-&gt;people），如果是Contradiction的时候，那么假设句中可能就有很多否定词之类的。这些特点其实很好理解，但是如果模型发现了这些特征，那么它甚至可以只用假设句就能进行分类，但结果正确并没有什么用，模型并没有真正理解语义。如图作者进行了一些统计分析，可以看到有一些词和标签是有着紧密联系了，可以直接用这些词进行分类，但这些对语义理解并没有什么帮助。因此如何避免这些情况，准确理解语义也是一个非常重要的研究内容。 最后以上就是我针对自然语言推理的一个简单介绍，作为自然语言理解的一个重要组成部分，这里边还是有很多很有意思的内容值得研究的。♪(＾∀＾●)ﾉ]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>natural language inference</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+github搭建个人博客记录]]></title>
    <url>%2F2018%2F05%2F26%2Fblog-start%2F</url>
    <content type="text"><![CDATA[作为一个工科生，但一直希望能够记录一些东西；同样作为一个工科生，有能力自己搭建博客。看了很多大神的github博客，最终决定也用hexo+github搭建一个自己的个人小站，记录下自己的一些足迹。 搭建步骤github建立repository在自己的github上新建repository，要注意的是name必须是username.github.io，该地址也是博客的地址，换成其他名字是不行的 hexo安装安装git和node.js git地址：https://git-scm.com/download/win node.js地址：https://nodejs.org/zh-cn/ 安装Hexo npm install -g hexo #-g表示全局安装, npm默认为当前项目安装 Hexo部署建立博客的根目录，（建议使用全英文目录，避免出现奇奇怪怪的bug），然后在该目录下打开git bash，（这里同样建议使用git bash，不使用windows terminal，因为windows terminal有一些log信息不会输出，这样就看不到哪里有问题了） hexo init #新建博客目录hexo g #根据当前目录下文件生成静态网页hexo s #启动服务器，还可以使用hexo s -p 4321，解决端口占用问题 这样就可以在浏览器中输入localhost:4000查看了， 简单介绍一下文件目录，摘自这里 public：执行hexo generate命令，输出的静态网页内容目录 scaffolds：layout模板文件目录，其中的md文件可以添加编辑 scripts：扩展脚本目录，这里可以自定义一些javascript脚本 source：文章源码目录，该目录下的markdown和html文件均会被hexo处理。该页面对应repo的根目录，404文件、favicon.ico文件，CNAME文件等都应该放这里，该目录下可新建页面目录。 drafts：草稿文章 posts：发布文章themes：主题文件目录 config.yml：全局配置文件，大多数的设置都在这里 package.json：应用程序数据，指明hexo的版本等信息，类似于一般软件中的 关于 按钮 Hexo 写文章 hexo new “postname” #然后在posts目录下的postname.md文件中编辑博客 然后在source目录下打开对应的markdown文件，编辑即可，这里建议使用typora Hexo本地调试 hexo clean #清除之前生成的内容，保证不出问题hexo g #生成hexo s #启动本地服务，进行文章预览调试，也可以使用hexo s -p 4321 Hexo部署到github上首先安装一个插件，保证能够使Hexo部署到GitHub上： npm install hexo-deployer-git –save 在博客目录下找到配置文件_config.yml，进行编辑 编辑前： # Deployment## Docs: http://hexo.io/docs/deployment.htmldeploy: type: 编辑后： deploy: type: git repo: 对应仓库的SSH地址（可以在GitHub对应的仓库中复制） branch: 分支（User Pages为master，Project Pages为gh-pages） 然后执行： hexo ghexo deploy 之后就可以在浏览器中通过username.github.io进行浏览，棒棒哒 优化部署和管理虽然目前已经基本搭建好了博客，但是编辑只能在当前电脑编辑，github上保存的是生成之后的html文件，整个博客的源代码都在本地，那如果想要在别的电脑上编辑怎么办，这时候就要利用到github的分支，即在建立博客仓库的时候，建立两个分支，一个用于展示网站内容，一个用于存放hexo文件， 具体流程参考了这里 创建流程 创建仓库，username.github.io； 创建两个分支：master 与 hexo； 设置hexo为默认分支（因为我们只需要手动管理这个分支上的Hexo网站文件）； 使用git clone git@github.com:username/username.github.io.git拷贝仓库； 在本地username.github.io文件夹下通过Git bash依次执行npm install hexo、hexo init、npm install 和 npm install hexo-deployer-git（此时当前分支应显示为hexo）; 修改_config.yml中的deploy参数，分支应为master； 依次执行git add .、git commit -m “…”、git push origin hexo提交网站相关的文件； 执行hexo generate -d生成网站并部署到GitHub上。 这样一来，在GitHub上的CrazyMilk.github.io仓库就有两个分支，一个hexo分支用来存放网站的原始文件，一个master分支用来存放生成的静态网页。 日常修改在本地对博客进行修改，一般是如下步骤 git pull (在保证本地没有修改的情况下，更新到github上的版本，保持版本一致，非常重要) 进行各种编辑，修改操作 依次执行git add .、git commit -m “…”、git push origin hexo指令将改动推送到GitHub（此时当前分支应为hexo） 然后才执行hexo generate -d发布网站到master分支上 异地修改当在不同的电脑上修改时，一般是如下步骤 使用git clone git@github.com:username/username.github.io.git拷贝仓库（默认分支为hexo） 在本地新拷贝的username.github.io文件夹下通过Git bash依次执行下列指令：npm install hexo、npm install、npm install hexo-deployer-git 然后就是日常修改中的2以后的操作 最后果然自己搭，坑不是一般的多，后续会慢慢更新，记录我在使用过程中踩过的坑↖(^ω^)↗]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F01%2F01%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. test2 Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <tags>
        <tag>others</tag>
      </tags>
  </entry>
</search>
